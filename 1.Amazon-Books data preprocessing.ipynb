{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7925df8a",
   "metadata": {},
   "source": [
    "- 사용할 data에 대해 먼저 설명을 해보겠습니다. 해당 data는 UCSD의 Jianmo Ni가 배포한 것([link](http://deepyeti.ucsd.edu/jianmo/amazon/))으로 Amazon의 책 판매 부문과 관련된 data입니다.\n",
    "- 데이터는 크게 두 부분으로 구성되어 있습니다. 1) user가 각 item들에 대해 5-stars scale로 rating을 한 log, 2) 각 item들(Amazon에서 판매하는 책)에 대한 meta-data로 이루어져 있습니다.\n",
    "- 원활한 설명을 위해 순서를 조금 바꾸어 설명하겠습니다. 두 번째로 언급했던 item의 meta data를 먼저 처리하고, 이를 바탕으로 첫 번째로 언급했던 rating log를 처리하겠습니다.\n",
    "- Preprocessing의 결과로 1) item들의 meta data -> item들의 ranking value, 2) rating log -> dictionary로 가공됩니다. 전처리 결과 각 user와 item들은 (0, 73058), (0, 160808) range의 숫자를 부여받습니다. rating log의 preprocessing의 결과인 dictionary는 training data와 test data로 나뉘게 되며 (key: user number, values: item numbers or 반대)의 형태로 가공됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2dceb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279520a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "data = []\n",
    "with gzip.open('./data/meta_Books.json.gz') as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0e4bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['category', 'tech1', 'description', 'fit', 'title', 'also_buy', 'tech2', 'brand', 'feature', 'rank', 'also_view', 'main_cat', 'similar_item', 'date', 'price', 'asin', 'imageURL', 'imageURLHighRes'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603b202f",
   "metadata": {},
   "source": [
    "- 해당 data를 전처리하여 사용하려는 목적은 다음과 같습니다. user와 item으로 Bipartite하게 나뉘어진 graph data에 대해, 각 user와 item이 connect 되었는지를 rating의 유무로 판단하여 관계를 포착하는 GCN(Graph Convolutional Network) based model을 사용할 때, 성능을 올리기 위한 feature로 무엇을 사용할 수 있을지를 찾아보는 것이 목적입니다.\n",
    "- item의 meta-data는 위에 ```keys()```를 통해 나온 결과처럼 다양한 data들이 포함되어 있습니다. 하지만 그 중 ranking을 사용하려는 이유는 가장 feature가 될 가능성이 있어보여서였습니다.\n",
    "- Category와 title, description, brand(작가의 이름) 등을 사용하여 user가 특정 부류의 책을 좋아하는 지를 포착해볼까 하는 생각도 했지만, 해당 feature들은 data에 결측치가 너무 많아 일반적으로 적용하기는 힘들어보였습니다.\n",
    "- 다음으로는 also_view, also_buy라는 feature가 있었지만, 이를 사용하는 것은 큰 의미가 없다고 생각했습니다. 우리가 보통 물건을 생각하는 과정을 고려해보았을 때, 여러가지 물건들을 '보고', 그 중에서 더 맘에 드는 것들을 골라 '구매'하고, 그 중에서 더 강렬한 감정(실망 혹은 기쁨)을 느낀 물건들에 후기를 달고 rating을 합니다. 이런 일련의 과정들을 생각해보았을 때, (보고, 구매하고, 평가를 한 것)들 중에서 가장 user의 선호를 잘 나타내는 것은 '평가를 한 물건들'이라고 생각하였습니다. 그런데 아래에서 rating log data를 전처리한 후 학습에 사용할 예정이기 때문에, also_view와 also_buy를 사용하는 것은 성능에 유의미한 향상을 가져오지는 못할 것이라 판단했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking Extract\n",
    "ranking_dict = dict() # key: asin(item code), value: rank\n",
    "except_rank = dict() # key: asin(item code), value: defective value\n",
    "for i in data:\n",
    "    try:\n",
    "        rank = re.sub(r'[^0-9]', '', i['rank'])\n",
    "        if rank == '':\n",
    "            except_rank[i['asin']] = i['rank']\n",
    "        else:\n",
    "            ranking_dict[i['asin']] = rank\n",
    "    except TypeError:\n",
    "        except_rank[i['asin']] = i['rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1efa1",
   "metadata": {},
   "source": [
    "- rank 역시 결측치가 어느정도 있어서 이를 처리해주어야 합니다. Regular expression을 사용하여 숫자만 추출하여 ```ranking_dict```에 저장하고, 숫자가 없거나 비어있는 경우엔 ```except_rank```에 저장해주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466e2e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Load\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001713353</th>\n",
       "      <td>A1C6M8LCIX4M6M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1123804800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001713353</th>\n",
       "      <td>A1REUF3A1YCPHM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1112140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001713353</th>\n",
       "      <td>A1YRBRK2XM5D5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1081036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001713353</th>\n",
       "      <td>A1V8ZR5P78P4ZU</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1077321600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001713353</th>\n",
       "      <td>A2ZB06582NXCIV</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1475452800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      item  user      rating\n",
       "0001713353  A1C6M8LCIX4M6M   5.0  1123804800\n",
       "0001713353  A1REUF3A1YCPHM   5.0  1112140800\n",
       "0001713353   A1YRBRK2XM5D5   5.0  1081036800\n",
       "0001713353  A1V8ZR5P78P4ZU   5.0  1077321600\n",
       "0001713353  A2ZB06582NXCIV   5.0  1475452800"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data Load\n",
    "print('Data Load')\n",
    "rating_data = pd.read_csv('./data/Books.csv', names = ['item', 'user', 'rating']) # five-stars rating\n",
    "rating_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c0669",
   "metadata": {},
   "source": [
    "- 다음 data는 rating log data입니다. raw data는 ```head()```로 출력한 바와 같습니다. 전처리 후에는 rating을 했는지 안 했는지의 여부만 dictionary의 형태로 남게 되고 몇점으로 rating 했는지에 대한 정보는 소실됩니다. 해당 정보(별점)까지 사용하기 위해서는 graph의 edge에 별점만큼 weight을 주어야 하는데, 그렇게 되면 모델이 훨씬 복잡해지기에 단순한 GCN based model을 사용한다는 목적에 부합하게 rating 여부만 사용하였습니다.(edge_weight을 사용하는 graph neural network는 GAT라는 model이 있습니다만 학습에 걸리는 시간이 현재 사용 예정인 model의 몇 백배 수준입니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e21336",
   "metadata": {},
   "outputs": [],
   "source": [
    "### user and item Grouping\n",
    "print('Data Grouping')\n",
    "rating_item_dict = dict(list(rating_data['user'].groupby(rating_data['item']))) # key: item code, value: user code\n",
    "rating_item_set = set()\n",
    "for i in rating_item_dict:\n",
    "    if (len(rating_item_dict[i]) >= 50) & (i in ranking_dict):\n",
    "        rating_item_set.add(i) # collect items that were rated by users more than 50 times and have ranking value\n",
    "\n",
    "rating_user_dict = dict(list(rating_data['item'].groupby(rating_data['user']))) # key: user code, value: item code\n",
    "rating_user_set = set()\n",
    "for i in rating_user_dict:\n",
    "    if len(rating_user_dict[i]) >= 50: # collect users that rated items more than 50 times\n",
    "        rating_user_set.add(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f1735",
   "metadata": {},
   "source": [
    "- rating log data는 일단 user와 item의 고유 code를 사용하여 각각 ```groupby()```함수를 통해 dictionary data로 grouping을 해줍니다. 이때 key는 user(or item)의 code이고, value는 item(or user)의 code입니다.\n",
    "- 그 다음 set에서는 50회 이상 rating을 한 user와, 50회 이상 rated된 item만 저장합니다. item의 경우 특별히 이에 더해 ranking dictionary에 해당 data가 있는지 확인(ranking의 결측치 확인)하는 과정도 추가됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32398717",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct user and item set for filtering\n",
    "processed_user = set()\n",
    "processed_item = set()\n",
    "\n",
    "for i in rating_item_set: # item set rated by users more than 50 times and have ranking value.\n",
    "    user_from_item = set(rating_item_dict[i].values)\n",
    "    temp = (user_from_item & rating_user_set)\n",
    "    if len(temp) >= 2:\n",
    "        processed_item.add(i)\n",
    "\n",
    "for i in rating_user_set: # user set rated more than 50\n",
    "    item_from_user = set(rating_user_dict[i].values)\n",
    "    temp = (item_from_user & processed_item)\n",
    "    if len(temp) >= 2:\n",
    "        processed_user.add(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8d4e5",
   "metadata": {},
   "source": [
    "- 위의 과정에선 Bipartite graph로 만들어지지 않는 data를 filtering합니다. 풀어서 설명하면, 이전 과정에서 50회 이상 rating을 한 user와 50회 이상 rated된 item만을 filtering하였는데, 해당 data들을 key로 삼아 기존 dictionary에서 조회한다면 당연히 value에는 50회 이상 rating을 하지 않은 user나 item이 조회될 것입니다. 이를 아래에서 training과 test data로 나눌 때 참조하여 filtering하기 위해 ```processed_user```와 ```processed_item``` set을 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ff0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_user_list = list(processed_user) # User codes are the elements, we will use this list's index as user's number\n",
    "processed_item_list = list(processed_item) # Item codes are the elements, we will use this list's index as item's number\n",
    "\n",
    "# training set\n",
    "train_user_item_dict = defaultdict(set) # key : user, value : item\n",
    "train_item_user_dict = defaultdict(set) # key : item, value : user\n",
    "# test set\n",
    "test_user_item_dict = defaultdict(set)\n",
    "test_item_user_dict = defaultdict(set)\n",
    "# overall set\n",
    "rating_set_all = defaultdict(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d5dc9",
   "metadata": {},
   "source": [
    "- ```processed_user_list```와 ```processed_item_list```를 만듭니다. 이는 아직까지 고유 code로 저장되어있는 각 user와 item에, 별도의 숫자로 mapping하는 과정없이, 해당 list의 index를 mapping되는 숫자로 사용하기 위함입니다.\n",
    "- 그 외에 training과 test set으로 저장하기 위한 dictionary를 선언하는데, user가 key이고 item이 value인 ```user_item_dict```와, item이 key이고 user가 value인 ```item_user_dict```를 나누어 선언합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change user and item codes into number and split into training and test dict ###\n",
    "print('Matrix making start')\n",
    "temp = set()\n",
    "for i in processed_user: # filtered users\n",
    "    item_from_user = set(rating_user_dict[i].values)\n",
    "    temp = (item_from_user & processed_item) # filtered items\n",
    "    count = len(temp)\n",
    "    if count >= 2:\n",
    "        user_index = int(processed_user_list.index(i))\n",
    "        item_codes = list(temp)\n",
    "        \n",
    "        ######################## 1st round ########################\n",
    "        not_included = [] # It means 'not included' in 'train_item_user_dict' yet -> should be assigned to that dict.\n",
    "        already_included = [] # It means 'already included' in 'train_item_user_dict'\n",
    "        for j in item_codes:\n",
    "            item_index = int(processed_item_list.index(j))\n",
    "            rating_set_all[user_index].add(item_index)\n",
    "            \n",
    "            if (item_index not in train_item_user_dict): # Is item_index in train_item_user_dict as 'key'?\n",
    "                not_included.append(item_index)# if not, there is no any item in train_item_user_dict related with\\\n",
    "                                               # this item key, fill train_item_user_dict with it first.\n",
    "            else:\n",
    "                already_included.append(item_index)\n",
    "        for j in not_included:\n",
    "            train_user_item_dict[user_index].add(j)\n",
    "            train_item_user_dict[j].add(user_index)\n",
    "            \n",
    "        ######################## 2nd round ########################\n",
    "        test_cut = math.ceil(count*0.2) # I want to split 8 : 2 = train : test dictionary\n",
    "        if len(already_included) != 0: \n",
    "            length = len(already_included) - test_cut # length for elements will go to training dict.\n",
    "            if length > 0:\n",
    "                for j in already_included[:length]:\n",
    "                    train_user_item_dict[user_index].add(j)\n",
    "                    train_item_user_dict[j].add(user_index)\n",
    "                for j in already_included[length:]:\n",
    "                    test_user_item_dict[user_index].add(j)\n",
    "                    test_item_user_dict[j].add(user_index)\n",
    "            else: # length == 0 -> assign to test dict\n",
    "                for j in already_included:\n",
    "                    test_user_item_dict[user_index].add(j)\n",
    "                    test_item_user_dict[j].add(user_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f891d",
   "metadata": {},
   "source": [
    "- 먼저 user를 ```processed_user```에서 받아옵니다. 그리고 해당 user-key의 value로 딸려있는 item들을 가져와서 ```processed_item```을 이용하여 한번 filtering을 진행합니다.\n",
    "- 1st round에서는 ```training_item_user_dict```(item이 key, user가 value)의 key인 item의 수가 ```processed_item```의 length만큼 되도록 하기 위해, test dataset보다 training dataset에 우선적으로 배정할 user-item pair를 선별합니다. 이렇게 하는 이유는 해당 data를 사용할 GCN based model인 LR-GCCF(Linear Residual Graph Convolutional Collaborative Filtering) model에서 ```training_user_item_dict```와 ```training_item_user_dict```을 사용하여 \\[user $\\times$ item\\], \\[item $\\times$ user\\] shape의 matrix를 만들고, 이를 각각 \\[item $\\times$ n\\], \\[user $\\times$ n\\]의 embedding matrix와 matrix multiplication을 하는 과정이 있기 때문입니다. 이때 matrix의 column과 row부분의 dimension이 맞아야 matrix multiplication을 할 수 있기 때문에 위와 같은 과정을 진행합니다.\n",
    "- 2nd round에서는 남은 data들을 가지고 training data와 test data에 8:2의 비율로 적절히 나눠줍니다.\n",
    "- 위와 같은 처리를 해줄 경우, test를 할 때 test data에 user에 대응되는 item이 없는 경우도 존재하지만, precision이 아니라 recall을 metric으로 사용할 것이기에 성능평가를 할 때 문제가 생기지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Count start')\n",
    "train_count = 0\n",
    "test_count = 0\n",
    "for i in train_user_item_dict: # count train data values\n",
    "    train_count = train_count + len(train_user_item_dict[i])\n",
    "for i in test_user_item_dict: # count test data values\n",
    "    test_count = test_count + len(test_user_item_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4cf8d4",
   "metadata": {},
   "source": [
    "- training data와 test data에 할당된 value(item)의 수를 카운트하고 저장하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea44576",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Make ranking list')\n",
    "ranking_list = []\n",
    "for i in processed_item_list: # i is a item code\n",
    "    ranking_list.append(ranking_dict[i]) # append ranking value in order(processed_item_list is ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb157bc2",
   "metadata": {},
   "source": [
    "- 이 과정에선 ranking을 item의 저장순서에 맞춰 list로 다시 저장합니다. ```processed_item_list```의 index를 각 item의 mapping된 number로 사용하기에, 이를 기준으로 ```ranking_list```를 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60055580",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Save as npy file')\n",
    "np.save('./training_set.npy', [train_user_item_dict, train_item_user_dict, train_count])\n",
    "np.save('./testing_set.npy', [test_user_item_dict, test_item_user_dict, test_count])\n",
    "np.save('./rating_set_all.npy', rating_set_all)\n",
    "np.save('./ranking_list.npy', ranking_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76760878",
   "metadata": {},
   "source": [
    "- 전처리 후엔 model에서 data를 load하여 사용할 수 있도록 ```.npy``` file format으로 저장합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
